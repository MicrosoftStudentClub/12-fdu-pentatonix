## Music Generation

复旦大学 pentatonix

郑逸宁 王沛晟 张曾光 王佳羽 王雪飞

### 项目文件

```
data\ 		存放训练与测试数据的文件夹
result\		存放生成音乐的文件夹
module.py	定义了解析mid文件所需的类和方法
main.py		用于分析数据文件
get_data.py	用于划分训练数据和测试数据
naive.py	用给予naive Bayes的方法生成音乐
```

### 数据获取与处理

​	我们使用了GitHub上mid格式的诺丁汉民歌进行音乐生成的项目（数据来源：https://github.com/jukedeck/nottingham-dataset ），并选取了其中melody中的长度合适的1000首歌曲，按4:1划分成训练数据集和测试数据集进行实验。

### 算法实现

1. 利用mido作为接口，从mid文件中导出每个音轨，并记录下来音轨中每个音符的音调和时长。
2. 记录连续音符二元组的频数，并转化成每个音符后续音符的频率分布表，用于下一步的实验。
3. 利用Naive Bayes的方法，每次选取一个音符后出现频率较高的若干（参数num）音符中的一个作为下一个音符。并从出现频率最高的若干个开头音符中选取首个音符，以此来生成长度（参数len）为8-32的旋律。
4. 使用不同的参数num和len生成若干组mid音乐，每组30个

### 训练和测试

​	我们利用训练数据集找出效果较好的num参数生成的结果，对len=8,16,32分组，与测试集中的音乐混合后，由志愿者试听，以判别是否可以以假乱真。经过我们的测验，我们在len=8的分组上取得了非常好的结果；但在len=16和32的分组，效果因人而异，有音乐训练经验的同学可以很容易的在这两组中分辨出生成的音乐和真实音乐。